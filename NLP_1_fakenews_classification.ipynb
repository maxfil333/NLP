{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b58076d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (1.24.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (2.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 640.0 kB/s eta 0:00:20\n",
      "     --------------------------------------- 0.1/12.8 MB 812.7 kB/s eta 0:00:16\n",
      "      --------------------------------------- 0.2/12.8 MB 1.5 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.4/12.8 MB 3.1 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.8/12.8 MB 4.8 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.3/12.8 MB 5.7 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.3/12.8 MB 5.7 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.6/12.8 MB 5.8 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.5/12.8 MB 8.0 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.9/12.8 MB 8.1 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 8.6 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 9.0 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.2/12.8 MB 9.0 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 4.6/12.8 MB 9.3 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 5.0/12.8 MB 9.5 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 9.7 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 5.8/12.8 MB 9.7 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 5.8/12.8 MB 9.7 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 6.7/12.8 MB 10.0 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 10.0 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 10.1 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 8.0/12.8 MB 10.2 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.4/12.8 MB 10.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.8/12.8 MB 10.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.3/12.8 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 10.5 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 10.1/12.8 MB 10.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.5/12.8 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 10.9/12.8 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 11.4/12.8 MB 11.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 11.8/12.8 MB 12.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 12.2/12.8 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.6/12.8 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 11.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.24.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ru-core-news-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.6.0/ru_core_news_sm-3.6.0-py3-none-any.whl (15.3 MB)\n",
      "     ---------------------------------------- 0.0/15.3 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/15.3 MB 330.3 kB/s eta 0:00:47\n",
      "     --------------------------------------- 0.0/15.3 MB 487.6 kB/s eta 0:00:32\n",
      "     ---------------------------------------- 0.1/15.3 MB 1.0 MB/s eta 0:00:15\n",
      "      --------------------------------------- 0.4/15.3 MB 2.5 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.6/15.3 MB 3.3 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.8/15.3 MB 3.6 MB/s eta 0:00:04\n",
      "     -- ------------------------------------- 1.1/15.3 MB 4.2 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.3/15.3 MB 4.7 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.6/15.3 MB 4.9 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.9/15.3 MB 5.4 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 2.3/15.3 MB 5.8 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.6/15.3 MB 6.2 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.9/15.3 MB 6.3 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 3.3/15.3 MB 6.6 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.7/15.3 MB 7.0 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 4.1/15.3 MB 7.3 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 4.5/15.3 MB 7.4 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 5.0/15.3 MB 7.7 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 5.4/15.3 MB 8.0 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.8/15.3 MB 8.0 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 6.0/15.3 MB 8.0 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 6.5/15.3 MB 8.3 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.9/15.3 MB 8.3 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 7.3/15.3 MB 8.5 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 7.7/15.3 MB 8.7 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 8.1/15.3 MB 8.8 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 8.6/15.3 MB 8.8 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 9.0/15.3 MB 9.0 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 9.4/15.3 MB 9.1 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 9.7/15.3 MB 9.1 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 9.7/15.3 MB 9.1 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 10.7/15.3 MB 10.4 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 11.1/15.3 MB 10.7 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 11.5/15.3 MB 10.9 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 11.9/15.3 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 12.3/15.3 MB 11.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 12.7/15.3 MB 11.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 13.2/15.3 MB 11.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 13.6/15.3 MB 11.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 14.0/15.3 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 14.4/15.3 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 14.8/15.3 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------------------------  15.2/15.3 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------------------------  15.2/15.3 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 15.3/15.3 MB 10.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from ru-core-news-sm==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: pymorphy3>=1.0.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from ru-core-news-sm==3.6.0) (1.2.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.6.0) (0.7.2)\n",
      "Requirement already satisfied: docopt-ng>=0.6 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.6.0) (2.4.417150.4580142)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (1.24.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\py311\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.1.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ru_core_news_sm')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "from string import punctuation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download ru_core_news_sm\n",
    "\n",
    "import spacy\n",
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22178351",
   "metadata": {},
   "source": [
    "## Получение данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4869d98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл успешно скачан.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/netology-ds-team/nlp-homeworks/main/7_Classification_in_AOT/Materials/Constraint_Train.csv'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(\"Constraint_Train.csv\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Файл успешно скачан.\")\n",
    "else:\n",
    "    print(\"Не удалось скачать файл. Статус код:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e5ae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet label\n",
       "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
       "1   2  States reported 1121 deaths a small rise from ...  real\n",
       "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
       "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
       "4   5  Populous states can generate large case counts...  real"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Constraint_Train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4811466a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'States reported 1121 deaths a small rise from last Tuesday. Southern states reported 640 of those deaths. https://t.co/YASGRTT4ux'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "104b223f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6420/6420 [00:01<00:00, 5536.74it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = [word_tokenize(text.lower()) for text in tqdm(df.tweet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feeffc69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['states',\n",
       " 'reported',\n",
       " '1121',\n",
       " 'deaths',\n",
       " 'a',\n",
       " 'small',\n",
       " 'rise',\n",
       " 'from',\n",
       " 'last',\n",
       " 'tuesday',\n",
       " '.',\n",
       " 'southern',\n",
       " 'states',\n",
       " 'reported',\n",
       " '640',\n",
       " 'of',\n",
       " 'those',\n",
       " 'deaths',\n",
       " '.',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/yasgrtt4ux']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787df45f",
   "metadata": {},
   "source": [
    "### 1. gensim.models.Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9507cfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.98 s\n",
      "Wall time: 1.46 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x185297ead10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model_tweets = Word2Vec(sentences, workers=6, vector_size=300, min_count=3, window=5, epochs=15)\n",
    "model_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7905028b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5266, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tweets.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2cce0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(text):\n",
    "    result = []\n",
    "    for word in word_tokenize(text.lower()):\n",
    "        if word in model_tweets.wv:\n",
    "            result.append(model_tweets.wv[word])\n",
    "\n",
    "    if len(result):\n",
    "        result = np.sum(result, axis=0)\n",
    "    else:\n",
    "        result = np.zeros(300)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56468514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6420/6420 [00:01<00:00, 3962.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [get_text_embedding(text) for text in tqdm(df.tweet)]\n",
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30fb8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, df.label, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a90b02ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0231f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.91      0.92       754\n",
      "        real       0.92      0.94      0.93       851\n",
      "\n",
      "    accuracy                           0.92      1605\n",
      "   macro avg       0.92      0.92      0.92      1605\n",
      "weighted avg       0.92      0.92      0.92      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803c315",
   "metadata": {},
   "source": [
    "### 2. sklearn.feature_extraction.text.CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6611c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "bow = vec.fit_transform(df.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88eb8610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vec.vocabulary_)=18385\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'{len(vec.vocabulary_)=}')\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow, df.label, test_size=0.25)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4aa1fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.94      0.94      0.94       794\n",
      "        real       0.94      0.94      0.94       811\n",
      "\n",
      "    accuracy                           0.94      1605\n",
      "   macro avg       0.94      0.94      0.94      1605\n",
      "weighted avg       0.94      0.94      0.94      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440ec12e",
   "metadata": {},
   "source": [
    "### 3. sklearn.feature_extraction.text.CountVectorizer + regex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0253723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6420/6420 [00:01<00:00, 6203.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['states', 'reported', '1121', 'deaths', 'a', 'small', 'rise', 'from', 'last', 'tuesday', '.', 'southern', 'states', 'reported', '640', 'of', 'those', 'deaths', '.', 'https', ':', '//t.co/yasgrtt4ux']\n",
      "['states', 'reported', '1121', 'deaths', 'a', 'small', 'rise', 'from', 'last', 'tuesday', '.', 'southern', 'states', 'reported', '640', 'of', 'those', 'deaths', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pattern = r'https://\\S+'\n",
    "re_sentences = [word_tokenize(re.sub(pattern, '', text.lower())) for text in tqdm(df.tweet)]\n",
    "print(sentences[1])\n",
    "print(re_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee3c710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "bow = vec.fit_transform([' '.join(x) for x in re_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51e3d41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vec.vocabulary_)=14315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'{len(vec.vocabulary_)=}')\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow, df.label, test_size=0.25)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e7369d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.91      0.94      0.92       758\n",
      "        real       0.94      0.92      0.93       847\n",
      "\n",
      "    accuracy                           0.93      1605\n",
      "   macro avg       0.93      0.93      0.93      1605\n",
      "weighted avg       0.93      0.93      0.93      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9553ec7",
   "metadata": {},
   "source": [
    "### 4. sklearn.feature_extraction.text.CountVectorizer + regex + spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb6160e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'cdc',\n",
       " 'currently',\n",
       " 'reports',\n",
       " '99031',\n",
       " 'deaths',\n",
       " 'in',\n",
       " 'general',\n",
       " 'the',\n",
       " 'discrepancies',\n",
       " 'in',\n",
       " 'death',\n",
       " 'counts',\n",
       " 'between',\n",
       " 'different',\n",
       " 'sources',\n",
       " 'are',\n",
       " 'small',\n",
       " 'and',\n",
       " 'explicable',\n",
       " 'the',\n",
       " 'death',\n",
       " 'toll',\n",
       " 'stands',\n",
       " 'at',\n",
       " 'roughly',\n",
       " '100000',\n",
       " 'people',\n",
       " 'today']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_re_sentences = []\n",
    "for lst in re_sentences:\n",
    "    lst = list(filter(lambda x: x not in punctuation, lst))\n",
    "    filtered_re_sentences.append(lst)\n",
    "    \n",
    "filtered_re_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65feabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4391753",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(os.path.isfile('fakenews.txt')):\n",
    "    lemmatized_sentences = []\n",
    "    for s in tqdm(filtered_re_sentences):\n",
    "        new_sentence = [token[0].lemma_ for token in map(nlp, s) if token[0].is_stop == False]\n",
    "        lemmatized_sentences.append(new_sentence)\n",
    "        \n",
    "    with open(\"fakenews.txt\", \"w\", encoding='utf-8') as file:\n",
    "        for sublist in lemmatized_sentences:\n",
    "            string = \" \".join(sublist) + \"\\n\"\n",
    "            file.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1af69245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cdc',\n",
       " 'currently',\n",
       " 'report',\n",
       " '99031',\n",
       " 'death',\n",
       " 'general',\n",
       " 'discrepancy',\n",
       " 'death',\n",
       " 'count',\n",
       " 'different',\n",
       " 'source',\n",
       " 'small',\n",
       " 'explicable',\n",
       " 'death',\n",
       " 'toll',\n",
       " 'stand',\n",
       " 'roughly',\n",
       " '100000',\n",
       " 'people',\n",
       " 'today']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fakenews_tweets = []\n",
    "with open(\"fakenews.txt\", \"r\", encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        fakenews_tweets.append(line.strip().split())\n",
    "        \n",
    "fakenews_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cdc15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "bow = vec.fit_transform(list(map(lambda x: ' '.join(x), fakenews_tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94a216d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vec.vocabulary_)=11460\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'{len(vec.vocabulary_)=}')\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow, df.label, test_size=0.25)\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb942cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.92      0.92      0.92       750\n",
      "        real       0.93      0.93      0.93       855\n",
      "\n",
      "    accuracy                           0.92      1605\n",
      "   macro avg       0.92      0.92      0.92      1605\n",
      "weighted avg       0.92      0.92      0.92      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa0e21d",
   "metadata": {},
   "source": [
    "### 5. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a80af133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d38bce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = (df.label == 'real').astype(int).to_list()\n",
    "labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dcbf981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "15.833489096573208\n",
      "840\n"
     ]
    }
   ],
   "source": [
    "minlen = len(min(fakenews_tweets, key=len))\n",
    "avglen = np.mean(list(map(len, fakenews_tweets)))\n",
    "maxlen = len(max(fakenews_tweets, key=len))\n",
    "print(minlen)\n",
    "print(avglen)\n",
    "print(maxlen)\n",
    "\n",
    "max_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c04a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 300\n",
    "total_examples = len(labels)\n",
    "seq_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11ddd6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 6420/6420 [00:00<00:00, 30666.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "for text in tqdm(fakenews_tweets):\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        if i < len(text):\n",
    "            word = text[i]\n",
    "            if word in model_tweets.wv.key_to_index:\n",
    "                embeddings.append(model_tweets.wv[word])\n",
    "            else:\n",
    "                embeddings.append(np.zeros(300, dtype=np.float32))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(300, dtype=np.float32))\n",
    "    \n",
    "    features.append(embeddings)\n",
    "\n",
    "features[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "772ca7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RNN_net, self).__init__()\n",
    "        self.rnn = nn.RNN(300, 100, batch_first=True)\n",
    "        self.linear = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        output = torch.sigmoid(self.linear(hidden)).squeeze()\n",
    "        return output\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, 100).to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c63a064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding batch: torch.Size([4, 30, 300])\n",
      "batch of hidden: torch.Size([1, 4, 100])\n",
      "linear output: tensor([0.4915, 0.4916, 0.4916, 0.4917], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "XXX = torch.tensor(np.array(features[0:4]))\n",
    "print('embedding batch:', XXX.shape)\n",
    "rnn = nn.RNN(300, 100, batch_first=True)\n",
    "_, hidden = rnn(XXX)\n",
    "print('batch of hidden:', hidden.shape)\n",
    "linear = nn.Linear(100, 1)\n",
    "lin = torch.sigmoid(linear(hidden))\n",
    "print('linear output:', lin.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20ca79fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_net(\n",
       "  (rnn): RNN(300, 100, batch_first=True)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RNN = RNN_net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_RNN.parameters(), lr=0.001)\n",
    "model_RNN.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "710d6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = map(np.array, train_test_split(features, labels, test_size=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa1cf116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, in_data, targets, batch_size=4):\n",
    "    for i in tqdm(range(0, len(X_train), batch_size)):\n",
    "        batch_x = torch.tensor(X_train[i:i + batch_size]).to(device)\n",
    "        batch_y = torch.tensor(y_train[i:i + batch_size]).float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "657f7a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1204/1204 [02:06<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5843, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1204/1204 [02:09<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5852, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1204/1204 [02:10<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6447, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1204/1204 [02:09<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5824, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1204/1204 [02:07<00:00,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6536, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  train_one_epoch(model_RNN, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdebf281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.8577e-04, 4.8577e-04, 4.8577e-04,  ..., 4.8577e-04, 9.9950e-01,\n",
       "        9.9950e-01], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model_RNN(torch.tensor(X_test).to(device))\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b26f417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 0, 1, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44cc3a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False,  ...,  True,  True,  True])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = (output.cpu() > 0.5) == torch.tensor(y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "267aafd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7514018691588785"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sum().item() / len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68962d",
   "metadata": {},
   "source": [
    "### 6. LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fcbaaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSTM_net, self).__init__()\n",
    "        self.lstm = nn.LSTM(300, 100, batch_first=True)\n",
    "        self.linear = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        output = torch.sigmoid(self.linear(hidden[1])).squeeze()\n",
    "        return output\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = (torch.zeros(1, batch_size, 100).to(device), \n",
    "                  torch.zeros(1, batch_size, 100).to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7202e545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (lstm): LSTM(300, 100, batch_first=True)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSTM = LSTM_net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_LSTM.parameters(), lr=0.001)\n",
    "model_LSTM.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "725f9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = map(np.array, train_test_split(features, labels, test_size=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8e75163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1204/1204 [02:07<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8997, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1204/1204 [02:11<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1017, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1204/1204 [02:11<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7957, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1204/1204 [02:09<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7925, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1204/1204 [02:09<00:00,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8253, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  train_one_epoch(model_LSTM, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2d9a8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2208e-03, 1.0000e+00, 9.9982e-01,  ..., 2.0860e-05, 9.9999e-01,\n",
       "        6.7255e-01], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model_LSTM(torch.tensor(X_test).to(device))\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51c5b154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d018b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  ..., False,  True, False])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = (output.cpu() > 0.5) == torch.tensor(y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41da625b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.881619937694704"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sum().item() / len(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
